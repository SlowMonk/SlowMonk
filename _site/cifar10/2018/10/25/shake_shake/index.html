<!DOCTYPE html>
<html lang="en"><!--
 __  __                __                                     __
/\ \/\ \              /\ \             __                    /\ \
\ \ \_\ \   __  __    \_\ \      __   /\_\      __       ___ \ \ \/'\
 \ \  _  \ /\ \/\ \   /'_` \   /'__`\ \/\ \   /'__`\    /'___\\ \ , <
  \ \ \ \ \\ \ \_\ \ /\ \L\ \ /\  __/  \ \ \ /\ \L\.\_ /\ \__/ \ \ \\`\
   \ \_\ \_\\/`____ \\ \___,_\\ \____\ _\ \ \\ \__/.\_\\ \____\ \ \_\ \_\
    \/_/\/_/ `/___/> \\/__,_ / \/____//\ \_\ \\/__/\/_/ \/____/  \/_/\/_/
                /\___/                \ \____/
                \/__/                  \/___/

Powered by Hydejack v6.4.0 (https://qwtel.com/hydejack/)
-->









<head>
  <!-- =============== -->
<!-- META            -->
<!-- =============== -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="format-detection" content="telephone=no">
<meta http-equiv="x-ua-compatible" content="ie=edge">
<meta name="naver-site-verification" content="22c5b4ef3bfda7fc6100671413989219de7a4ac8"/>
<meta property="og:title" content="CIFAR-10 정복 시리즈 3: Shake-Shake">
<meta property="og:type" content="article">





  <meta property="og:image" content="http://localhost:4003/assets/img/logo.png">


<meta property="og:image:width" content="640" />
<meta property="og:image:height" content="360" />



  <title>CIFAR-10 정복 시리즈 3: Shake-Shake &middot; Woongwon Lee</title>



<meta name="description" content="CIFAR-10 정복하기 시리즈 소개
CIFAR-10 정복하기 시리즈에서는 딥러닝이 CIFAR-10 데이터셋에서 어떻게 성능을 높여왔는지 그 흐름을 알아본다. 또한 코드를 통해서 동작원리를 자세하게 깨닫고 실습해볼 것이다.

">
<meta property="og:description" content="CIFAR-10 정복하기 시리즈 소개
CIFAR-10 정복하기 시리즈에서는 딥러닝이 CIFAR-10 데이터셋에서 어떻게 성능을 높여왔는지 그 흐름을 알아본다. 또한 코드를 통해서 동작원리를 자세하게 깨닫고 실습해볼 것이다.

">



<!-- =============== -->
<!-- LINKS           -->
<!-- =============== -->
<link rel="canonical" href="http://localhost:4003/cifar10/2018/10/25/shake_shake/">
<meta property="og:url" content="http://localhost:4003/cifar10/2018/10/25/shake_shake/">

<link rel="alternate" type="application/atom+xml" title="Woongwon Lee Feed" href="http://localhost:4003/feed.xml">


  <link rel="prev" href="http://localhost:4003/cifar10/2018/10/24/pyramidnet/">



  <link rel="next" href="http://localhost:4003/writing/2019/01/01/writing-practice-13/">


<link rel="apple-touch-icon" href="http://localhost:4003/apple-touch-icon.png">
<link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
<!-- Place favicon.ico in the root directory -->

<!-- =============== -->
<!-- SCRIPTS         -->
<!-- =============== -->
<script>
  !function(n,e){function t(n,e){n.onload=function(){this.onerror=this.onload=null,e(null,n)},n.onerror=function(){this.onerror=this.onload=null,e(new Error("Failed to load "+this.src),n)}}function o(n,e){n.onreadystatechange=function(){"complete"!=this.readyState&&"loaded"!=this.readyState||(this.onreadystatechange=null,e(null,n))}}n._loaded=!1,n.loadJSDeferred=function(a,d){function r(){n._loaded=!0;var r=e.createElement("script");r.src=a,d&&(("onload"in r?t:o)(r,d),r.onload||t(r,d));var l=e.getElementsByTagName("script")[0];l.parentNode.insertBefore(r,l)}n._loaded?r():n.addEventListener?n.addEventListener("load",r,!1):n.attachEvent?n.attachEvent("onload",r):n.onload=r}}(window,document);

  !function(e){"use strict";var n=function(n,t,o){function i(e){if(a.body)return e();setTimeout(function(){i(e)})}function r(){l.addEventListener&&l.removeEventListener("load",r),l.media=o||"all"}var d,a=e.document,l=a.createElement("link");if(t)d=t;else{var f=(a.body||a.getElementsByTagName("head")[0]).childNodes;d=f[f.length-1]}var s=a.styleSheets;l.rel="stylesheet",l.href=n,l.media="only x",i(function(){d.parentNode.insertBefore(l,t?d:d.nextSibling)});var u=function(e){for(var n=l.href,t=s.length;t--;)if(s[t].href===n)return e();setTimeout(function(){u(e)})};return l.addEventListener&&l.addEventListener("load",r),l.onloadcssdefined=u,u(r),l};"undefined"!=typeof exports?exports.loadCSS=n:e.loadCSS=n}("undefined"!=typeof global?global:this);

  !function(t){if(t.loadCSS){var e=loadCSS.relpreload={};if(e.support=function(){try{return t.document.createElement("link").relList.supports("preload")}catch(t){return!1}},e.poly=function(){for(var e=t.document.getElementsByTagName("link"),r=0;r<e.length;r++){var n=e[r];"preload"===n.rel&&"style"===n.getAttribute("as")&&(t.loadCSS(n.href,n,n.getAttribute("media")),n.rel=null)}},!e.support()){e.poly();var r=t.setInterval(e.poly,300);t.addEventListener&&t.addEventListener("load",function(){e.poly(),t.clearInterval(r)}),t.attachEvent&&t.attachEvent("onload",function(){t.clearInterval(r)})}}}(this);

  window.disablePushState = false;
  window.disableDrawer = false;
</script>
<!--
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-5105555504153863",
    enable_page_level_ads: true
  });
</script>
-->
<!--[if lt IE 9]>
<script src="https://unpkg.com/html5shiv/dist/html5shiv.min.js"></script>
<![endif]-->

<!-- =============== -->
<!-- STYLES          -->
<!-- =============== -->
<!--[if gt IE 8]><!---->
<style>
  
  article,aside,dialog,figcaption,figure,footer,header,hgroup,main,nav,section{display:block}mark{background:#FF0;color:#000}*{box-sizing:border-box}html,body{margin:0;padding:0}html{font-size:16px;line-height:1.75}body{color:#333;background-color:#fff;overflow-y:scroll}a{text-decoration:none}.lead{margin-left:-1rem;margin-right:-1rem}img,.img{display:block;max-width:100%;margin-bottom:1rem;border:none}img.lead,.img.lead{max-width:calc(100% + 2rem);width:calc(100% + 2rem)}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6,.heading{font-weight:bold;text-rendering:optimizeLegibility}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6{margin:1.6rem 0 1rem;line-height:1.6}h1,.h1{font-size:2rem;line-height:1.25}h2,.h2{font-size:1.5rem}h3,.h3{font-size:1.17em}p{margin-top:0;margin-bottom:1rem}p.lead{font-size:1.25rem;font-weight:300;padding:0 1rem}ul,ol,dl{margin-top:0;margin-bottom:1rem}ul,ol{padding-left:1.25rem}hr{position:relative;margin:1.5rem 0;border:0;border-top:1px solid #eee}.hr{padding-bottom:.5rem;border-bottom:1px solid #eee;margin-bottom:1.5rem}h4,h5,h6,.h4,.h5,.h6{margin-bottom:0.5rem;font-size:1rem}table{margin-bottom:1rem;width:100%;width:calc(100% + 2rem);margin-left:-1rem;border:1px solid #e5e5e5;border-collapse:collapse;border-spacing:0}td,th{padding:.25rem .5rem;border:1px solid #e5e5e5}td:first-child,th:first-child{padding-left:1rem}td:last-child,th:last-child{padding-right:1rem}thead+tbody,tbody+tbody,tfoot{border-top:3px double #e5e5e5}tbody tr:nth-child(odd) td,tbody tr:nth-child(odd) th{background-color:#f9f9f9}footer{margin-bottom:2rem}.page,.post{margin-bottom:3em}.page li+li,.post li+li{margin-top:.25rem}.page>header,.post>header{margin-bottom:2rem}.page-title,.post-title{margin-top:0}.post-date{display:block;margin-top:-0.5rem;margin-bottom:1rem;color:#9a9a9a}.related-posts{padding-left:0;list-style:none}.related-posts>li,.related-posts>li+li{margin-top:1rem}.related-posts>li>small,.related-posts>li+li>small{font-size:75%;color:#9a9a9a}.message{margin-bottom:1rem;padding:1rem;color:#787878;background-color:#f9f9f9;margin-left:-1rem;margin-right:-1rem}body,main{position:relative;overflow-x:hidden}@media screen{body::before{content:'';background:#e5e5e5;position:absolute;left:0;top:0;bottom:0}}@media screen and (min-width: 40em){html{font-size:17px}}@media screen and (min-width: 54em){html{font-size:16px}}@media screen and (min-width: 88em){html{font-size:17px}}@media screen and (min-width: 125em){html{font-size:18px}}.sr-only{display:none}.clearfix,.sidebar-social::after,.clearafter::after{content:"";display:table;clear:both}a,.a{position:relative;padding-bottom:.15rem;border-style:hidden}.img{overflow:hidden;background-color:#f9f9f9}.img>img{margin:0;width:100%;height:100%}.sixteen-nine{position:relative}.sixteen-nine::before{display:block;content:"";width:100%;padding-top:56.25%}.sixteen-nine>*{position:absolute;top:0;left:0;right:0;bottom:0}h1+hr,h2+hr,h3+hr,h4+hr,h5+hr,h6+hr{margin-top:0}.fade-in{animation-duration:500ms;animation-name:fade-in;animation-fill-mode:forwards}@keyframes fade-in{from{transform:translateY(-2rem);opacity:0}50%{transform:translateY(-2rem);opacity:0}to{transform:translateY(0);opacity:1}}.mb6{margin-bottom:10rem}.sidebar{color:rgba(255,255,255,0.75);text-align:left}.sidebar::before{content:"";position:absolute;z-index:2;top:0;left:0;bottom:0;right:0;background:linear-gradient(to bottom, rgba(32,32,32,0) 0%, rgba(32,32,32,0.5) 100%)}.sidebar a{color:#fff;border-bottom-color:rgba(255,255,255,0.2)}.right-side{width:100%;margin-left:auto;margin-right:auto}.right-side .ad-first{text-align:center}.right-side .ad-second{text-align:center}@media screen{.right-side{max-width:38rem;min-height:100vh}}@media screen and (min-width: 54em){.right-side{margin-left:20rem;margin-right:1rem;padding:4rem 1rem 12rem}}@media screen and (min-width: 72em){.right-side{margin-left:22rem;max-width:42rem}}@media screen and (min-width: 88em){.right-side{width:162px;margin-left:0rem;margin-right:0rem;padding:0rem;margin-top:10rem;display:block;float:left}}@media screen and (min-width: 96em){.right-side{width:300px;margin-right:0rem}}#_yDrawer{position:relative}@media screen{#_yDrawer{min-height:640px;min-height:100vh}}@media screen and (min-width: 54em){#_yDrawer{width:18rem;margin-left:0}}.sidebar-bg{position:absolute;height:100%;overflow:hidden;top:0;right:0;bottom:0;left:0;background:#202020 center / cover}.sidebar-box{display:flex;justify-content:center}.sidebar-sticky{position:relative;z-index:3}@media screen{.sidebar-sticky{-ms-overflow-style:none;overflow:-moz-scrollbars-none;height:100%;overflow:auto;position:absolute;padding:3rem 0rem;right:2.5rem;left:2.5rem}}.sidebar-sticky::-webkit-scrollbar{display:none}.sidebar-about>h1{color:#fff;font-size:2rem}.sidebar-nav>ul{list-style:none;padding-left:0;margin-bottom:.5rem}a.sidebar-nav-item{width:100%;font-weight:normal;display:block;line-height:1.75;padding:.25rem 0;border-bottom:1px solid rgba(255,255,255,0.2)}a.sidebar-nav-subitem{font-weight:normal;display:block;line-height:1.75;padding:.25rem 0;border-bottom:1px solid rgba(255,255,255,0.2)}@media screen{.y-drawer-scrim{z-index:2}.y-drawer-content{width:18rem;left:-18rem;z-index:3}}.sidebar-social{margin-bottom:.5rem}.sidebar-social>ul{list-style:none;padding-left:0;margin:0 -.25rem}.sidebar-social>ul>li{float:left}.sidebar-social>ul>li>a{display:inline-block;text-align:center;font-size:1.6rem;line-height:3rem;width:3.1249rem;height:4rem;padding:.5rem 0}.sidebar-social>ul li+li{margin-top:0}.fixed-top{position:fixed;top:0;left:0;width:100%;z-index:1}.navbar>.content{padding-top:0;padding-bottom:0;min-height:0;height:0}.menu{display:inline-block;padding:1.75rem 1.5rem;border-bottom:none;margin-left:-1.5rem;color:#9a9a9a !important}.menu::after{content:"\2630"}@media screen and (min-width: 54em){.menu{padding:1.25rem 1.5rem;position:absolute;left:-9999px}.menu:focus{position:static}}.animation-main{pointer-events:none}.loading{display:none}@media print{.menu{display:none}}.animation-main{opacity:0;will-change:opacity}.loading{position:absolute;top:0;right:0;padding:5.25rem 4.5rem;transform-origin:top right;transform:scale(0.33)}.content{position:relative;margin-left:auto;margin-right:auto;padding:5rem 1rem 12rem}@media screen{.content{min-height:100vh}}@media screen and (min-width: 54em){.content{padding:4rem 1rem 12rem;margin-left:19rem;margin-right:3rem}}@media screen and (min-width: 72em){.content{max-width:42rem;margin-left:21rem}}@media screen and (min-width: 88em){.content{float:left;width:100%;margin-left:22rem;margin-right:5rem}}@media screen and (min-width: 96em){.content{max-width:44rem}}@media screen and (min-width: 102em){.content{margin-left:25rem;margin-right:8rem}}.me{width:6.5rem;height:6.5rem;align-self:center;margin-right:20px;border-radius:100%;position:relative}@media screen and (min-width: 40em){.me{width:7rem;height:7rem}}@media screen and (min-width: 54em){.me{width:6.5rem;height:6.5rem}}@media screen and (min-width: 72em){.me{width:7rem;height:7rem}}main>footer{width:100%;position:absolute;bottom:0;left:0;right:0;padding:0 1rem;color:#9a9a9a;font-size:smaller;text-align:center}main>footer>p{margin-bottom:0}html{font-family:'Sans-serif'}h1,h2,h3,h4,h5,h6,.h1,.h2,.h3,.h4,.h5,.h6,.heading{font-family:'Sans-serif'}

</style>


<link rel="preload" href="http://localhost:4003/assets/css/hydejack.css?v=6.4.0" as="style" onload="this.rel='stylesheet'">

<style id="_pageStyle">

.content a{color:#4f86aa;border-color:rgba(79,134,170,0.2)}.content a:hover{border-color:#4f86aa}:focus{outline-color:#4f86aa}::selection{color:#fff;background:#4f86aa}::-moz-selection{color:#fff;background:#4f86aa}

</style>


<noscript>
  <link rel="stylesheet" href="http://localhost:4003/assets/css/hydejack.css?v=6.4.0">
  
  
  

  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
    <style>
      html { font-family: 'Lato', 'Sans-serif' }
      h1, h2, h3, h4, h5, h6, .h1, .h2, .h3, .h4, .h5, .h6, .heading { font-family: 'Lato', 'Sans-serif' }
    </style>
  

  
  <link rel="stylesheet" href="http://localhost:4003/assets/icomoon/style.css">
</noscript>
<!--<![endif]-->

</head>

<body>
  <!-- =============== -->
<!-- MENU            -->
<!-- =============== -->
<div class="navbar fixed-top">
  <div class="content">
    <span class="sr-only">Jump to:</span>
    <a id="_menu" class="menu no-hover" href="#_title">
      <span class="sr-only">Menu</span>
    </a>
  </div>
</div>

<!-- =============== -->
<!-- CONTENT         -->
<!-- =============== -->
<div id="_yPushState">
  <div class="fade-in">
    <main id="_main" class="content" role="main" data-color="#4f86aa" data-image="/assets/img/nap.jpg">
      

<article id="post-cifar10/2018/10/25/shake_shake" class="post" role="article">
  <header>
    <h1 class="post-title">
      
        CIFAR-10 정복 시리즈 3: Shake-Shake
      
    </h1>

    <p class="post-date heading">
      <time datetime="2018-10-25T00:00:00+09:00">25 Oct 2018</time>
      









in <span>Cifar10</span>

      









on <a href="/tag/paper-dl/" data-flip="title">Deep-Learning</a>

    </p>

    <script data-ad-client="ca-pub-2252618542833203" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    
  <div class="hr" style="padding-bottom:0"></div>


  </header>
  
    <!--
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  -->
  
    <div class="markdown-body">


        <!--
<style>
.myAd1190 { display:block; width:98%; height: 280px; }
@media(min-width: 600px) { .myAd1190 { display: none; } }
</style>
<ins class="adsbygoogle myAd1190"
    data-ad-client="ca-pub-5105555504153863"
    data-ad-slot="6481487416"
    ></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
-->


<br/>
      <h2 id="cifar-10-정복하기-시리즈-소개">CIFAR-10 정복하기 시리즈 소개</h2>
<p>CIFAR-10 정복하기 시리즈에서는 딥러닝이 CIFAR-10 데이터셋에서 어떻게 성능을 높여왔는지 그 흐름을 알아본다. 또한 코드를 통해서 동작원리를 자세하게 깨닫고 실습해볼 것이다.</p>

<ul>
  <li>CIFAR-10 정복하기 시리즈 목차(클릭해서 바로 이동하기)
    <ul>
      <li><a href="https://dnddnjs.github.io/cifar10/2018/10/07/start_cifar10/">CIFAR-10 정복 시리즈 0: 시작하기</a></li>
      <li><a href="https://dnddnjs.github.io/cifar10/2018/10/09/resnet/">CIFAR-10 정복 시리즈 1: ResNet</a></li>
      <li><a href="https://dnddnjs.github.io/cifar10/2018/10/24/pyramidnet/">CIFAR-10 정복 시리즈 2: PyramidNet</a></li>
      <li><a href="https://dnddnjs.github.io/cifar10/2018/10/25/shake_shake/">CIFAR-10 정복 시리즈 3: Shake-Shake</a></li>
    </ul>
  </li>
  <li>관련 코드 링크
    <ul>
      <li><a href="https://github.com/dnddnjs/pytorch-cifar10">pytorch cifar10 github code</a></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="cifar-10-정복-시리즈-3-shake-shake">CIFAR-10 정복 시리즈 3: Shake-Shake</h2>
<p>이전 포스트에서는 ResNet의 구조를 변형시킨 모델을 알아봤다. PyramidNet은 학습할 때 error rate가 거의 0이라고 볼 수 있다. 학습 error rate에 비해 테스트 error rate는 여전히 높기 때문에 regularization에 대해 생각해봐야한다. CIFAR은 학습 데이터양이 적은데 비해 네트워크의 representation power는 높다. 따라서 <strong>overfit</strong>이 일어나기 쉽다. CIFAR에서의 overfit 문제를 해결하고자 하는 것이 <strong>Shake-Shake regularization</strong><sup id="fnref:0"><a href="#fn:0" class="footnote">1</a></sup>이다. Shake-Shake는 네트워크의 forward pass와 backward pass에서 noise를 주는 방식이다. 하지만 Shake-Shake는 <strong>ResNeXt</strong><sup id="fnref:1"><a href="#fn:1" class="footnote">2</a></sup>의 구조의 네트워크에만 적용할 수 있다. 이 post에서는 Shake-Shake를 살펴보도록 하겠다.</p>

<ol>
  <li><a href="#resnext">ResNeXt</a></li>
  <li><a href="#fractalnet">FractalNet</a></li>
  <li><a href="#shake-shake">Shake-Shake</a></li>
  <li><a href="#code-review">Code Review</a></li>
  <li><a href="#squeeze-and-excitation">Squeeze and Excitation</a></li>
</ol>

<p><br /></p>

<p>딥러닝에서 regularization은 overfit을 방지하기 위한 방법으로 많이 사용되고 있다. 그동안 사용되어왔던 regularization 효과를 가지는 방법들로는 weight decay, dropout, batch-normalization, SGD 등이 있다. PyramidNet 포스트에서 살펴봤던 ResDrop 또한 regularization에 해당한다. 네트워크 자체는 점점 강력해지지만 generalization 성능은 그만큼 따라오지 않기 때문에 이 이외에 추가적인 노력이 이어졌다. 기존 residual block는 2 branch로 구성되어있다. 한 branch는 idenity mapping이고 다른 branch는 nonlinear computation이 이뤄진다. <strong>ResNeXt</strong>는 이런 기본적인 구성을 벗어나서 2개의 branch 이상의 n개의 branch를 사용한다. <strong>FractalNet</strong><sup id="fnref:2"><a href="#fn:2" class="footnote">3</a></sup>의 경우도 ResNeXt와 유사하게 여러 개의 subpath를 사용한다. FractalNet은 drop path라는 regularization 방법을 사용한다. <strong>Shake-Shake</strong>는 ResNeXt와 drop path를 적절히 합친 것이라고 볼 수 있다. 따라서 Shake-Shake를 살펴보기 전에 ResNeXt와 FractalNet을 간단히 살펴보겠다.</p>

<p><br /></p>

<h2 id="resnext">ResNeXt</h2>
<p>ResNeXt는 기본적으로 <strong>multi-branch ResNet이</strong>라고 보면 된다. 기존에 residual block을 design할 때 activation의 순서를 바꿔보거나(pre-activation ResNet) 혹은 convolution의 filter 수를 변화시켰다(WideResNet, PyramidNet). 하지만 ResNeXt는 그 이외에 <strong>cardinality</strong>라는 개념을 소개한다. 다음 그림에서 왼쪽이 일반적인 residual block이다. 오른쪽이 ResNeXt의 residual block이다. Shortcut connection은 그대로 하나이지만 residual 부분이 여러개인 것을 볼 수 있다. Cardinality는 residual의 개수이다. 여러 path의 output은 summation으로 합친다.</p>

<figure>
  <img src="https://www.dropbox.com/s/whhjpdfwzkcoahu/Screenshot%202018-11-23%2019.58.46.png?dl=1" width="400px" />
  <figcaption>
    https://arxiv.org/pdf/1611.05431.pdf
  </figcaption>
</figure>

<p><br /></p>

<p>ResNeXt의 multi-branch는 GoogLeNet의 <strong>Inception module</strong><sup id="fnref:3"><a href="#fn:3" class="footnote">4</a></sup>과 상당히 유사하다. 다음 그림의 Inception module이다. ResNeXt의 residual block은 Inception module과 다르게 각 path마다 모두 동일한 구조를 지니며 dimension이 모두 같다. Inception module은 hyper parameter가 많기 때문에 디자인하기 어렵다면 ResNeXt는 단순히 몇 개의 path를 사용하는지만 설정하기 때문에 상당히 간편하다.</p>

<figure>
  <img src="https://www.dropbox.com/s/frvr8g5vaojayw7/Screenshot%202018-11-23%2020.04.08.png?dl=1" />
  <figcaption>
    https://arxiv.org/pdf/1409.4842.pdf
  </figcaption>
</figure>

<p><br /></p>

<h2 id="fractalnet">FractalNet</h2>
<p>FractalNet은 Residual을 학습시키는 기존의 ResNet 변형체들과 다른 방식이다. FractalNet은 Residual을 학습하는 방식을 사용하지 않아도 네트워크를 깊게 쌓을 수 있다는 것을 보여준다. 아래 그림이 FractalNet의 fractal block의 구조를 보여준다. 가장 왼쪽은 fractal block을 형성하는 기본적인 방법을 보여준다. 보통 <code class="MathJax_Preview">f_C</code><script type="math/tex">f_C</script>로는 convolution을 사용하는데 확장할 때는 하나의 convolution이 오른쪽에 두 개로 합쳐진다. 그 다음 왼쪽에 다른 하나의 convolution을 붙이고 그 출력들을 join 연산을 통해 합친다. 이렇게 만든 fractal block은 가운데 그림과 같다. Residual block에서 볼 수 있는 residual과 identity mapping의 구조는 볼 수 없다.</p>

<figure>
  <img src="https://www.dropbox.com/s/kngx40hcgf8bg45/Screenshot%202018-11-23%2020.25.40.png?dl=1" width="500px" />
  <figcaption>
    https://arxiv.org/pdf/1605.07648.pdf
  </figcaption>
</figure>

<p><br /></p>

<p>기존 residual block에서는 2 branch가 identity mapping과 residual learning 이라는 각자의 역할을 수행했다. 하지만 fractal block의 경우 여러 path가 존재하는데 서로 중복된 역할을 할 수 있다. Dropout이 이러한 <strong>co-adaptation</strong> 문제를 해결하려고 하나의 neuron 단위에 적용되었다. Fractal block에서는 <strong>co-adapatation</strong> 문제를 해결하기 위해 path를 drop 해버리는 drop path를 사용한다. Drop path의 작동하는 예시는 다음 그림과 같다. Drop path는 두 가지 방식으로 작동한다. Local 방식은 다음 그림에서 형광색에 해당하는 join layer에서 랜덤하게 인풋을 drop해버린다. Global 방식은 두 번째, 네 번째 그림에서 보듯이 전체 block 내부에서 하나의 path만 선택한다. 이렇게 path를 drop해버리는 것으로 regularization 효과를 볼 수 있다.</p>

<figure>
  <img src="https://www.dropbox.com/s/ednae8p9cag0hin/Screenshot%202018-11-23%2020.26.01.png?dl=1" width="500px" />
  <figcaption>
    https://arxiv.org/pdf/1605.07648.pdf
  </figcaption>
</figure>

<p><br /></p>

<p>다음은 FractalNet의 실험결과이다. 20 layers에 38.6M 사이즈의 FractalNet을 보면 CIFAR-10에서 augmentation이 없을 경우 10.18 %의 error rate를 얻는 것을 볼 수 있다. 하지만 drop-path와 dropout을 사용할 경우 3% 정도의 성능이 향상된다. Data augmentation을 적용한 CIFAR-10에 대해서도 0.6 % 정도의 성능 향상을 볼 수 있다.</p>

<figure>
  <img src="https://www.dropbox.com/s/2tqzbx4lxti64g5/Screenshot%202018-11-23%2023.53.07.png?dl=1" />
  <figcaption>
    https://arxiv.org/pdf/1605.07648.pdf
  </figcaption>
</figure>

<p><br /></p>

<h2 id="shake-shake">Shake-Shake</h2>
<p>Shake-Shake는 ResNeXt와 Drop-path를 합친 것이라고 볼 수 있다. ResNeXt에서 여러 branch의 output을 합칠 때 단순히 summation으로 합친다. 하지만 Shake-Shake에서는 stochastic affine transform을 통해서 합치겠다는 것이 아이디어이다. 다음 그림이 Shake-Shake의 작동 방식을 알려준다. ResNeXt의 경우 32개의 branch까지도 사용했는데 Shake-Shake에서는 2개의 branch만 사용한다. 이 2개의 branch를 사용해서 regularization 하는 것이 핵심이다. Shake-Shake는 forward pass에서 한 번, backward pass에서 한 번 <strong>stochastic affine transform</strong>을 수행한다. 이 affine transform은 일종의 <strong>augmentation</strong>이라고 볼 수 있다.</p>

<figure>
  <img src="https://www.dropbox.com/s/t2ijf2ahf5dkxa1/Screenshot%202018-10-13%2019.32.12.png?dl=1" width="500px" />
  <figcaption>
    https://arxiv.org/pdf/1705.07485.pdf
  </figcaption>
</figure>

<p><br />
Shake-Shake에서 특정 block의 forward는 다음 수식과 같다. <code class="MathJax_Preview">\alpha</code><script type="math/tex">\alpha</script>는 확률변수로서 0에서 1 사이의 랜덤한 숫자이다. 하나의 path는 <code class="MathJax_Preview">\alpha</code><script type="math/tex">\alpha</script>를 곱하고 다른 하나의 path는 <code class="MathJax_Preview">1-\alpha</code><script type="math/tex">1-\alpha</script>를 곱해서 더한 것이 residual이 된다. <code class="MathJax_Preview">\alpha</code><script type="math/tex">\alpha</script>는 학습할 때 매 mini-batch마다 새로 뽑는다. Backward pass에서도 비슷하게 <code class="MathJax_Preview">\beta</code><script type="math/tex">\beta</script>라는 0에서 1 사이의 확률변수를 뽑아서 두 개의 다른 path로 가는 gradient에 그 값을 곱해준다. 위 그림에서 두 번째가 backward pass를 의미한다. 세 번째는 test 할 때를 말하는 것인데 test 할 때는 두 개의 path에 0.5씩 곱한 다음에 더한다. Shake-Shake는 drop path와 같이 하나의 path를 없애버리는 방식이 아니라 두 개의 path를 랜덤하게 섞어버리는 방식을 사용했다. 이러한 방식을 Shake-Shake 만의 novelty라고 볼 수 있다.</p>

<pre class="MathJax_Preview"><code>x_{i+1} = x_i + \alpha_i F(x_i, W_i^{(1)}) + (1- \alpha_i )F(x_i, W_i^{(2)})</code></pre>
<script type="math/tex; mode=display">x_{i+1} = x_i + \alpha_i F(x_i, W_i^{(1)}) + (1- \alpha_i )F(x_i, W_i^{(2)})</script>

<p><br /></p>

<p>Forward pass와 backward pass에서는 각각 <code class="MathJax_Preview">\alpha</code><script type="math/tex">\alpha</script>와 <code class="MathJax_Preview">\beta</code><script type="math/tex">\beta</script>라는 random number를 뽑아야한다. 이 때 새로운 <code class="MathJax_Preview">\alpha, \beta</code><script type="math/tex">\alpha, \beta</script>를 뽑는 방법에는 여러 가지가 있다. Pass 할 때마다 새로운 random number를 뽑는 것을 “Shake”라고 하며 <code class="MathJax_Preview">\alpha</code><script type="math/tex">\alpha</script>와 <code class="MathJax_Preview">\beta</code><script type="math/tex">\beta</script>를 따로 따로 pass마다 새로 뽑는 것을 <strong>Shake-Shake</strong>라고 한다. Shake-Shake 방식이 제일 성능이 좋기 때문에 논문의 이름이 Shake-Shake Regularization이 된 것이다. 다음 표는 여러가지 random number 추출 방식에 따른 성능 비교를 보여준다. Shake-Shake Image 방식이 <strong>2.86%</strong>로 가장 높은 성능을 달성한 것을 볼 수 있다. Level이라는 것이 있는데 Batch는 <code class="MathJax_Preview">\alpha, \beta</code><script type="math/tex">\alpha, \beta</script>를 하나의 mini-batch 안에서 공유하겠다는 것이고 Image는 <code class="MathJax_Preview">\alpha, \beta</code><script type="math/tex">\alpha, \beta</script>를 mini-batch안의 image마다 다르게 사용하겠다는 것을 뜻한다.</p>

<figure>
  <img src="https://www.dropbox.com/s/1cso45sjfpj7aap/Screenshot%202018-11-24%2000.17.41.png?dl=1" width="500px" />
  <figcaption>
    https://arxiv.org/pdf/1705.07485.pdf
  </figcaption>
</figure>

<p>Shake-Shake 모델은 3개의 stage를 가지는데 각 stage는 4개의 residual block으로 구성된다. 따라서 네트워크 전체의 깊이는 26이 된다. 위 표에서 Model 부분에 26 2x96d라고 써져있는데 이건 네트워크가 26층의 깊이를 가지며 2개의 branch를 사용하고 첫 residual block의 width가 96이라는 것을 의미한다. 2점대의 error rate라는 꽤나 인상적인 결과를 보여주는 Shake-Shake의 코드를 한 번 살펴보자.</p>

<p><br /></p>

<h2 id="code-review">Code Review</h2>
<p>코드에서는 Shake-Shake 26 2-32d 모델을 살펴볼 것이다. Shake-Shake의 residual block은 다음과 같다. 각 부분을 따로 살펴보겠다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ShakeBlock</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">down_sample</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ShakeBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">residual_branch1</span> <span class="o">=</span> <span class="n">ResidualBranch</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">residual_branch2</span> <span class="o">=</span> <span class="n">ResidualBranch</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">down_sample</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="n">SkippingBranch</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">down_sample</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">shake_shake</span> <span class="o">=</span> <span class="n">ShakeShake</span><span class="p">.</span><span class="nb">apply</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">residual_branch1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">residual_branch2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">out1</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">training</span><span class="p">:</span>        
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">shake_shake</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">shake_shake</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

        <span class="n">skip</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">down_sample</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span> <span class="o">+</span> <span class="n">skip</span>
</code></pre></div></div>

<p><br /></p>

<p>Residual branch는 따로 class로 정의를 해놓았다. 각각의 branch는 self.residual_branch1과 self.residual_branch2로 정의한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="bp">self</span><span class="p">.</span><span class="n">residual_branch1</span> <span class="o">=</span> <span class="n">ResidualBranch</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
<span class="bp">self</span><span class="p">.</span><span class="n">residual_branch2</span> <span class="o">=</span> <span class="n">ResidualBranch</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>

</code></pre></div></div>

<p><br />
residual branch의 코드는 다음과 같다. 일반적인 Residual block에서 residual branch에 해당하는 부분만 들어있다. Residual branch는 ReLU-Conv3x3-BN-ReLU-Conv3x3-BN-Mul 으로 구성된다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ResidualBranch</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ResidualBranch</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                               <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> 
        <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                               <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> 
        <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bn2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>

</code></pre></div></div>

<p><br />
다시 ShakeBlock으로 돌아간다. Residual Branch를 통해 정의된 residual branch들은 각각 out1, out2의 출력을 낸다. nn.Module을 상속할 경우 self.training을 통해 학습 중인지 아닌지를 알아낼 수 있다. 만약 학습 중이라면 self.training이 True가 되고 이 때 alpha와 beta를 image 단위로 랜덤하게 뽑아야한다. torch.rand라는 함수를 사용해서 alpha와 beta를 sampling한 다음에 feature dimension에 맞춰준다. out1과 out2에 alpha를 적용하는 함수가 self.shake_shake이며 custom module로 따로 정의되어있다. 이 때 beta도 함께 인자로 넣어주는데 pytorch에서 forward pass에서의 값을 저장해놓고 backpropagation을 하기 때문에 forward pass에서 beta의 정보를 넣어줘야한다. self.shake_shake에서 반환된 out은 shortcut과 더힌다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">shortcut</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">residual_branch1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">residual_branch2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">out1</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">training</span><span class="p">:</span>        
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">shake_shake</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">shake_shake</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>

    <span class="n">shortcut</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">down_sample</span><span class="p">(</span><span class="n">shortcut</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span> <span class="o">+</span> <span class="n">shortcut</span>
</code></pre></div></div>

<p><br /></p>

<p>self.shake_shake는 ShakeShake라는 클래스를 통해 정의된다. ShakeShake는 Shake-Shake 코드의 핵심이라고 할 수 있다. 이 코드를 작성할 때 pytorch tutorial<sup id="fnref:4"><a href="#fn:4" class="footnote">5</a></sup>과 pytorch discuss<sup id="fnref:5"><a href="#fn:5" class="footnote">6</a></sup>를 참고했다. 원래 backpropagation 할 때는 forward pass에서 곱해졌던 상수값을 기억해서 gradient에 곱해준다. 하지만 Shake-Shake에서는 forward pass와 backward pass에서 다른 상수값을 사용하기 때문에 이와 같이 custom을 해야 한다. ctx.save_for_backward에 인자로 넣으면 backward 할 때 그 값들을 호출할 수 있다. backward 함수에서 아까 저장했던 tensor를 불러온다. 불러온 <code class="MathJax_Preview">\beta</code><script type="math/tex">\beta</script>값을 각각의 branch로 내려가는 두 개의 gradient에 곱해준다. 한 gradient에는 <code class="MathJax_Preview">\beta</code><script type="math/tex">\beta</script>를 곱하고 한 branch에는 <code class="MathJax_Preview">1 - \beta</code><script type="math/tex">1 - \beta</script>를 곱해준다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ShakeShake</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">ctx</span><span class="p">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">input1</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">input2</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">):</span>
        <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">saved_tensors</span>
        <span class="n">grad_input1</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">grad_output</span>
        <span class="n">grad_input2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad_output</span>
        <span class="k">return</span> <span class="n">grad_input1</span><span class="p">,</span> <span class="n">grad_input2</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
</code></pre></div></div>

<p><br /></p>

<p>ShakeBlock의 forward pass에서 shortcut을 downsampling 하는데 보통 downsample의 방식과는 다르다. 보통 residual block에서 shortcut connection을 down sample 할 때 feature map의 사이즈를 반으로 줄이고 channel 수를 2배로 늘린다. ResNet에서는 max-pooling으로 사이즈를 반으로 줄이고 zero-padding으로 channel 수를 늘렸다. Shake-Shake에서는 특이하게도 입력을 2개의 branch를 만들어서 channel 방향으로 concatenate 한다. 첫 번째 branch는 들어온 입력을 average pooling한 이후에 1x1 convolution을 통과시킨다. 두 번째 branch에서는 입력을 왼쪽 위로 1 step만큼 shift한 이후에 padding을 통해 원래 입력의 feature map size를 유지한다. 그 이후에 1x1 convolution을 통과시킨다. 두 branch의 output인 out1과 out2를 channel 방향으로 concatenate 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">SkippingBranch</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SkippingBranch</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">avg_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span> 
                   <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
  

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>
    
        <span class="n">shift_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">:]</span>
        <span class="n">shift_x</span><span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">pad</span><span class="p">(</span><span class="n">shift_x</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    
        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">shift_x</span><span class="p">)</span>
        <span class="n">out2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>
    
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out1</span><span class="p">,</span> <span class="n">out2</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div>

<p><br /></p>

<p>Shake-Shake 네트워크의 전체 구조는 ShakeResNet에 정의되어 있다. ResNet의 전체 네트워크 코드와 동일하다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ShakeResNet</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ShakeResNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">16</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span><span class="o">=</span> <span class="n">num_layers</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                 <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># feature map size = 32x32x32
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">stage1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_layers</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># feature map size = 32x32x64
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">stage2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_layers</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># feature map size = 32x32x128
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">stage3</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_layers</span><span class="p">(</span><span class="n">block</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
        <span class="bp">self</span><span class="p">.</span><span class="n">avg_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">fc_out</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'fan_out'</span><span class="p">,</span> 
                                        <span class="n">nonlinearity</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">nn</span><span class="p">.</span><span class="n">init</span><span class="p">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">get_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">block</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">stride</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">down_sample</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">down_sample</span> <span class="o">=</span> <span class="bp">False</span>
    
        <span class="n">layers_list</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">block</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">down_sample</span><span class="p">)])</span>
      
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layers_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">block</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">))</span>

        <span class="k">return</span> <span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bn1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">stage1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">stage2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">stage3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">avg_pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">fc_out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</code></pre></div></div>

<p><br /></p>

<p>일반적인 ResNet과 또 다른 점은 학습 epoch 수이다. Shake-Shake는 forward pass와 backward pass에 일종의 노이즈를 주입하기 때문에 regularization 효과를 보는 대신 학습이 느려진다. 따라서 기존 ResNet과 같이 일정 update step마다 learning rate를 0.1배 하는 것은 맞지 않다. 대신 <strong>cosine annealing</strong><sup id="fnref:6"><a href="#fn:6" class="footnote">7</a></sup>을 사용한다. Cosine annealing은 learning rate를 cosine 함수의 형태로 decay 하겠다는 것이다. 다음 그림이 cosine annealing에서 learning rate가 iteration에 따라 어떻게 감소하는지를 보여준다. 처음 몇 epoch 동안은 높은 learning rate로 빠르게 local minimum을 찾고 그 이후 learning rate를 decay하면서 minimum에 가까이 다가가고 마지막 epcoh 동안에는 천천히 움직이다가 학습을 마무리한다.</p>

<figure>
  <img src="https://www.dropbox.com/s/6rcn2w05zye3yhz/Screenshot%202018-11-26%2000.13.33.png?dl=1" width="400px" />
  <figcaption>
    https://towardsdatascience.com/https-medium-com-reina-wang-tw-stochastic-gradient-descent-with-restarts-5f511975163
  </figcaption>
</figure>

<p><br /></p>

<p>Cosine annealing은 코드로 다음과 같이 구현할 수 있다. PyTorch의 lr_scheduler에서 custom learning rate scheduling을 할 수 있는 LambdaLR을 사용한다. 결국 cosin_annealing 함수를 호출하는 것이다. 이 함수에서는 lr_max에서 lr_min 까지 decay하는 함수의 형태를 정의하고 있다. Shake-Shake에서 첫 learning rate 곧 lr_max는 0.2이고 annealing을 1800 epoch 동안 수행한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_cosine_annealing</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">total_steps</span><span class="p">,</span> <span class="n">lr_max</span><span class="p">,</span> <span class="n">lr_min</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">lr_min</span> <span class="o">+</span> <span class="p">(</span><span class="n">lr_max</span> <span class="o">-</span> <span class="n">lr_min</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span>
        <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">step</span> <span class="o">/</span> <span class="n">total_steps</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">cosine_annealing_scheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">LambdaLR</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">lr_lambda</span><span class="o">=</span><span class="k">lambda</span> <span class="n">step</span><span class="p">:</span> <span class="n">_cosine_annealing</span><span class="p">(</span>
            <span class="n">step</span><span class="p">,</span>
            <span class="n">epochs</span><span class="p">,</span>
            <span class="n">lr</span><span class="p">,</span>  <span class="c1"># since lr_lambda computes multiplicative factor
</span>            <span class="mi">0</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">scheduler</span>
</code></pre></div></div>

<p><br /></p>

<p>Shake-Shake 네트워크의 학습 과정은 다음과 같다. 다른 네트워크에 비해 1800 epoch을 학습하기 때문에 학습이 오래 걸린다. Best test error는 3.79%이다.</p>

<p><img src="https://www.dropbox.com/s/1ptvuux24wr5qwj/Screenshot%202018-11-27%2014.42.56.png?dl=1" /></p>

<p><br /></p>

<h2 id="squeeze-and-excitation">Squeeze and Excitation</h2>

<p><br /></p>

<h3 id="참고문헌">참고문헌</h3>
<div class="footnotes">
  <ol>
    <li id="fn:0">
      <p>https://arxiv.org/pdf/1705.07485.pdf <a href="#fnref:0" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
    <li id="fn:1">
      <p>https://arxiv.org/pdf/1611.05431.pdf <a href="#fnref:1" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
    <li id="fn:2">
      <p>https://arxiv.org/pdf/1605.07648.pdf <a href="#fnref:2" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
    <li id="fn:3">
      <p>https://arxiv.org/pdf/1409.4842.pdf <a href="#fnref:3" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
    <li id="fn:4">
      <p>https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html <a href="#fnref:4" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
    <li id="fn:5">
      <p>https://discuss.pytorch.org/t/why-input-is-tensor-in-the-forward-function-when-extending-torch-autograd/9039 <a href="#fnref:5" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
    <li id="fn:6">
      <p>https://arxiv.org/pdf/1608.03983.pdf <a href="#fnref:6" class="reversefootnote">&#x21a9;&#xfe0e;</a></p>
    </li>
  </ol>
</div>

      <br/>
      <br/>
        <!--블로그-하단-반응형
      <ins class="adsbygoogle"
          style="display:block; width:100%; height:300px;"
          data-ad-client="ca-pub-5105555504153863"
          data-ad-slot="1037589043"
          data-ad-format="auto"></ins>
      <script>
      (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      -->
    </div>
  

</article>

  <hr class="dingbat" />

  <div class="share">
      <h2>Share this post</h2>
      <div class="share-body">
        <a href="http://twitter.com/share?text=CIFAR-10 정복 시리즈 3: Shake-Shake&amp;url=http://localhost:4003/cifar10/2018/10/25/shake_shake/"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
            <span class="icon-twitter">
            </span>
        </a>
        <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4003/cifar10/2018/10/25/shake_shake/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
            <span class="icon-facebook">
            </span>
        </a>
    </div>
  </div>
  <br/>






  <aside class="author" role="complementary">
    <div class="author">
  <h2 class="page-title hr">
    About
  </h2>
<div class="author-body">
  
    
  

  

  <img
    src="/assets/img/me.jpeg"
    class="me"
    alt="woongwon lee"
    srcset="/assets/img/me.jpeg 1x,/assets/img/me.jpeg 2x"
    
  />


  
  <div class="author-body-description">
    <p>Machine Learning Engineer</p>

  </div>
</div>
</div>

  </aside>





<aside class="related" role="complementary">
  <h2 class="hr">Related Posts</h2>

  <ul class="related-posts">
    
      
      
      
        
          
          
        
        
          


<li class="h4">
  <a href="/cifar10/2018/10/24/pyramidnet/" data-flip="title">
    <span>CIFAR-10 정복 시리즈 2: PyramidNet</span>
  </a>
  <small><time datetime="2018-10-24T00:00:00+09:00">
    24 Oct 2018
  </time></small>
</li>

        
      
        
        
          


<li class="h4">
  <a href="/cifar10/2018/10/09/resnet/" data-flip="title">
    <span>CIFAR-10 정복 시리즈 1: ResNet</span>
  </a>
  <small><time datetime="2018-10-09T00:00:00+09:00">
    09 Oct 2018
  </time></small>
</li>

        
      
        
        
          


<li class="h4">
  <a href="/cifar10/2018/10/07/start_cifar10/" data-flip="title">
    <span>CIFAR-10 정복 시리즈 0: 시작하기</span>
  </a>
  <small><time datetime="2018-10-07T00:00:00+09:00">
    07 Oct 2018
  </time></small>
</li>

        
      
    
  </ul>
</aside>



      
        <aside class="comments" role="complementary">
  <h2>Comments</h2>
  <hr/>

  <div id="disqus_thread"></div>

  <script>
    !function(s,i){function e(e){var t=s.pageYOffset||i.body.scrollTop;s.DISQUS&&!s._disqusThis&&!s._disqusFirst&&t+s.innerHeight>=s._disqusThreadOffsetTop&&(s._disqusThis=!0,s.DISQUS.reset({reload:!0,config:d}))}var d=function(){this.page.title="CIFAR-10 정복 시리즈 3: Shake-Shake",this.page.identifier="/cifar10/2018/10/25/shake_shake",this.page.url="http://localhost:4003/cifar10/2018/10/25/shake_shake/"};s._disqusFirst=void 0===s._disqusFirst||s._disqusFirst,s._disqusLoading=void 0!==s._disqusLoading&&s._disqusLoading,s._disqusThis=!1,s._disqusThreadOffsetTop=i.getElementById("disqus_thread").offsetTop,s._disqusLoading?s._disqusFirst=!1:(s._disqusLoading=!0,loadJSDeferred("//dnddnjs.disqus.com/embed.js"),s.addEventListener?s.addEventListener("scroll",e,{passive:!0}):s.attachEvent?s.attachEvent("onscroll",e):s.onscroll=e)}(window,document);

  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</aside>

      

      <footer>
  <hr/>
  
    <p>© 2018. by Woongwon Lee</p>

  
  <p>
    <code>Powered by <a href="https://dnddnjs.github.io/">dnddnjs</a></code>
  </p>
</footer>

    </main>
    <!--<div class="right-side">
  <div class="ad-first">
    <!--
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <!-- 블로그-상단-모바일
    <ins class="adsbygoogle"
         style="display:inline-block;width:100%;"
         data-ad-client="ca-pub-5105555504153863"
         data-ad-slot="9090558636"
         data-ad-format="auto"></ins>
    <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
    -->
  </div>
<br/>
<br/>
  <!--
  <div class="ad-second">
    <!-- 블로그-스카이스크래퍼
    <ins class="adsbygoogle"
         style="display:inline-block;max-width:320px;width:100%;height:600px"
         data-ad-client="ca-pub-5105555504153863"
         data-ad-slot="3646660262"></ins>
    <script>
    (adsbygoogle = window.adsbygoogle || []).push({});
    </script>
    -->
  </div>
</div>

-->
  </div>
  <div id="_yDrawer">
  <div id="_sidebar" class="sidebar">
    <div class="sidebar-bg" style="background-color:#4f86aa;background-image:url(/assets/img/nap.jpg)"></div>
    <header class="sidebar-sticky" role="banner">
      <br/>
      <div class="sidebar-about">
        <h1><a id="_title" href="/">Woongwon Lee</a></h1>
        <p>Machine Learning Engineer</p>

      </div>

      <br/>
      <br/>
      <nav class="sidebar-nav heading" role="navigation">
        <span class="sr-only">Navigation:</span>
<ul>
  

  

  
  
  
  
  
    <li>
      <input type="checkbox" id="list-item-1"/>
      <div  class="list-wrapper">
      <a class="sidebar-nav-item" href="/category/paper/">Paper</a>
       <label class="folder" for="list-item-1">▾</label>
    </div>
     <ul class="list-body">
       
           
         
           
         
           
             <li>
               <a class="sidebar-nav-subitem" href="/tag/paper-rl/">Reinforcement-Learning</a>
             </li>
           
         
           
         
           
             <li>
               <a class="sidebar-nav-subitem" href="/tag/paper-dl/">Deep-Learning</a>
             </li>
           
         
           
         
           
             <li>
               <a class="sidebar-nav-subitem" href="/tag/paper-thinking/">Thinking</a>
             </li>
           
         
     </ul>
    </li>

  
  
    <li>
      <input type="checkbox" id="list-item-2"/>
      <div  class="list-wrapper">
      <a class="sidebar-nav-item" href="/about/">About</a>
       
    </div>
     <ul class="list-body">
       
           
         
           
         
           
         
           
         
           
         
           
         
           
         
     </ul>
    </li>

  
</ul>

      </nav>
    <br/>
    <br/>
      <div class="sidebar-box">
        
          
  

  

  <img
    src="/assets/img/me.jpeg"
    class="me"
    alt="woongwon lee"
    srcset="/assets/img/me.jpeg 1x,/assets/img/me.jpeg 2x"
    
  />


        
      </div>
      <p>Reinforce Yourself</p>

      
      
        <div class="sidebar-social">
          <span class="sr-only">Social:</span>
<ul>
  
    









<li>
  <a href="https://facebook.com/dnddnjs">
    <span class="icon-facebook" title="Facebook"></span>
    <span class="sr-only">Facebook</span>
  </a>
</li>

  
    









<li>
  <a href="https://github.com/dnddnjs">
    <span class="icon-github" title="GitHub"></span>
    <span class="sr-only">GitHub</span>
  </a>
</li>

  
    









<li>
  <a href="mailto:dnddnjs11@naver.com">
    <span class="icon-mail" title="Email"></span>
    <span class="sr-only">Email</span>
  </a>
</li>

  
</ul>

        </div>
      
    </header>
  </div>
</div>

</div>

<!-- =============== -->
<!-- SCRIPTS         -->
<!-- =============== -->

<script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-120080215-1', 'auto');
  ga('send', 'pageview');
  loadJSDeferred('https://www.google-analytics.com/analytics.js');
</script>





<!--[if gt IE 8]><!---->
<script src="//ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js"></script>
<script>
  WebFont.load({
    
    google: {
      families: 'Lato'.split('|')
    },
    

    custom: {
      families: ['icomoon'],
      urls: ['/assets/icomoon/style.css']
    }
  });
</script>
<!--<![endif]-->


  <!--[if gt IE 9]><!---->
  
  <script>loadJSDeferred('/assets/js/hydejack.js?v=6.4.0');</script>

  
  <!--<![endif]-->



</body>

</html>
